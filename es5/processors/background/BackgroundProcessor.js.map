{"version":3,"file":"BackgroundProcessor.js","sourceRoot":"","sources":["../../../lib/processors/background/BackgroundProcessor.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA,6CAAmD;AAEnD,+CAA8C;AAE9C,0CAAyC;AACzC,uFAAwH;AAqExH;;GAEG;AACH;IAAoL,uCAAS;IAiB3L,6BACE,2BAA8B,EAC9B,OAAmC;QAFrC,YAIE,iBAAO,SAmBR;QAnCO,+BAAyB,GAAY,KAAK,CAAC;QAClC,uBAAiB,GAAoB,IAAI,eAAe,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QAC/D,wBAAkB,GAAsC,KAAI,CAAC,iBAAiB,CAAC,UAAU,CAAC,IAAI,EAAE,EAAE,kBAAkB,EAAE,IAAI,EAAE,CAAE,CAAC;QACxI,oBAAc,GAAmB,IAAI,CAAC;QACtC,qBAAe,GAAW,4BAAgB,CAAC;QAC3C,wBAAkB,GAA6B,IAAI,CAAC;QACpD,+BAAyB,GAAkE,IAAI,CAAC;QAExG,wCAAwC;QACxC,8CAA8C;QAC7B,cAAQ,GAAW,iBAAO,CAAC;QASxC,IAAA,UAAU,GAGR,OAAO,WAHC,EACV,KAEE,OAAO,yBAFgD,EAAzD,wBAAwB,mBAAG,KAAI,CAAC,yBAAyB,KAAA,EACzD,KACE,OAAO,eAD4B,EAArC,cAAc,mBAAG,KAAI,CAAC,eAAe,KAAA,CAC3B;QAEZ,IAAI,OAAO,UAAU,KAAK,QAAQ,EAAE;YAClC,MAAM,IAAI,KAAK,CAAC,uCAAuC,CAAC,CAAC;SAC1D;QAED,uDAAuD;QACvD,KAAI,CAAC,WAAW,GAAG,UAAU,CAAC,OAAO,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC;QACxD,KAAI,CAAC,4BAA4B,GAAG,2BAA2B,CAAC;QAChE,yFAAyF;QACzF,KAAI,CAAC,UAAU,GAAG,KAAI,CAAC,4BAA4B,CAAC,UAAU,CAAC;QAC/D,KAAI,CAAC,wBAAwB,GAAG,wBAAwB,CAAC;QACzD,KAAI,CAAC,cAAc,GAAG,cAAc,CAAC;;IACvC,CAAC;IAMD,sBAAI,yDAAwB;QAJ5B;;;WAGG;aACH;YACE,OAAO,IAAI,CAAC,yBAAyB,CAAC;QACxC,CAAC;QAED;;;;WAIG;aACH,UAA6B,KAAc;YACzC,IAAI,OAAO,KAAK,KAAK,SAAS,EAAE;gBAC9B,OAAO,CAAC,IAAI,CAAC,qDAAqD,CAAC,CAAC;gBACpE,KAAK,GAAG,IAAI,CAAC,yBAAyB,CAAC;aACxC;YACD,IAAI,IAAI,CAAC,yBAAyB,KAAK,KAAK,EAAE;gBAC5C,IAAI,CAAC,yBAAyB,GAAG,KAAK,CAAC;gBACvC,IAAI,CAAC,4BAA4B,CAAC,2BAA2B,CAC3D,IAAI,CAAC,yBAAyB,CAC/B,CAAC,KAAK,CAAC;oBACN,UAAU;gBACZ,CAAC,CAAC,CAAC;aACJ;QACH,CAAC;;;OApBA;IAyBD,sBAAI,+CAAc;QAHlB;;WAEG;aACH;YACE,OAAO,IAAI,CAAC,eAAe,CAAC;QAC9B,CAAC;QAED;;WAEG;aACH,UAAmB,MAAc;YAC/B,IAAI,OAAO,MAAM,KAAK,QAAQ,IAAI,MAAM,GAAG,CAAC,EAAE;gBAC5C,OAAO,CAAC,IAAI,CAAC,kDAA2C,4BAAgB,iBAAc,CAAC,CAAC;gBACxF,MAAM,GAAG,4BAAgB,CAAC;aAC3B;YACD,IAAI,IAAI,CAAC,eAAe,KAAK,MAAM,EAAE;gBACnC,IAAI,CAAC,eAAe,GAAG,MAAM,CAAC;gBAC9B,IAAI,CAAC,4BAA4B;qBAC9B,iBAAiB,CAAC,IAAI,CAAC,eAAe,CAAC;qBACvC,KAAK,CAAC;oBACL,UAAU;gBACZ,CAAC,CAAC,CAAC;aACN;QACH,CAAC;;;OAlBA;IAoBD;;;;OAIG;IACG,uCAAS,GAAf;;;;;;wBACE,KAAA,IAAI,CAAA;wBAAkB,qBAAM,IAAI;iCAC7B,4BAA4B;iCAC5B,gBAAgB,EAAE,EAAA;;wBAFrB,GAAK,cAAc,GAAG,SAED,CAAC;;;;;KACvB;IAED;;;;;;;;;;;;;;;;;;;;;;OAsBG;IACG,0CAAY,GAAlB,UACE,gBAAqF,EACrF,iBAAoC;;;;;;wBAEpC,IAAI,CAAC,gBAAgB,IAAI,CAAC,iBAAiB,EAAE;4BAC3C,MAAM,IAAI,KAAK,CAAC,sCAAsC,CAAC,CAAC;yBACzD;wBAEK,KAIF,IAAI,EAHN,4BAA4B,kCAAA,EAC5B,UAAU,gBAAA,EACV,yBAAyB,+BAAA,CAClB;wBAET,UAAU,CAAC,GAAG,CAAC,mBAAmB,CAAC,CAAC;wBACpC,UAAU,CAAC,GAAG,CAAC,sBAAsB,CAAC,CAAC;wBACvC,UAAU,CAAC,KAAK,CAAC,sBAAsB,CAAC,CAAC;wBACzC,UAAU,CAAC,KAAK,CAAC,mBAAmB,CAAC,CAAC;wBAGhC,KAGF,IAAI,CAAC,mBAAmB,CAAC,gBAAgB,CAAC,EAFrC,YAAY,WAAA,EACX,aAAa,YAAA,CACwB;wBAE/C,IAAI,IAAI,CAAC,kBAAkB,KAAK,iBAAiB,EAAE;4BACjD,IAAI,CAAC,kBAAkB,GAAG,iBAAiB,CAAC;4BAC5C,IAAI,CAAC,yBAAyB,GAAG,iBAAiB,CAAC,UAAU,CAAC,IAAI,CAAC;mCAC9D,iBAAiB,CAAC,UAAU,CAAC,gBAAgB,CAAC,CAAC;yBACrD;wBACD,IAAI,IAAI,CAAC,iBAAiB,CAAC,KAAK,KAAK,YAAY,EAAE;4BACjD,IAAI,CAAC,iBAAiB,CAAC,KAAK,GAAG,YAAY,CAAC;yBAC7C;wBACD,IAAI,IAAI,CAAC,iBAAiB,CAAC,MAAM,KAAK,aAAa,EAAE;4BACnD,IAAI,CAAC,iBAAiB,CAAC,MAAM,GAAG,aAAa,CAAC;yBAC/C;wBAKD,IAAI,gBAAgB,YAAY,gBAAgB,EAAE;4BAChD,IAAI,CAAC,kBAAkB,CAAC,SAAS,CAAC,gBAAgB,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;4BAC1D,UAAU,GAAG,IAAI,CAAC,iBAAiB,CAAC;yBACrC;6BAAM;4BACL,UAAU,GAAG,gBAAgB,CAAC;yBAC/B;6BAGmB,CAAA,4BAA4B,YAAY,yDAA2B,CAAA,EAAnE,wBAAmE;wBACnF,qBAAM,4BAA4B,CAAC,MAAM,CAAC,UAAU,CAAC,EAAA;;wBAArD,KAAA,SAAqD,CAAA;;4BACrD,qBAAM,4BAA4B,CAAC,MAAM,CACvC,UAAU,YAAY,eAAe;4BACnC,CAAC,CAAC,UAAU,CAAC,qBAAqB,EAAE;4BACpC,CAAC,CAAC,UAAwB,CAAC,kHAAkH;yBAC9I,EAAA;;wBAJH,KAAA,SAIG,CAAA;;;wBAND,WAAW,KAMV;wBAEP,qEAAqE;wBACrE,IAAI,yBAAyB,YAAY,2BAA2B,EAAE;4BAC9D,YAAY,GAAG,WAAW,YAAY,eAAe;gCACzD,CAAC,CAAC,WAAW,CAAC,qBAAqB,EAAE;gCACrC,CAAC,CAAC,WAAW,CAAC;4BAChB,yBAAyB,CAAC,uBAAuB,CAAC,YAAY,CAAC,CAAC;yBACjE;6BAAM,IAAI,yBAAyB,YAAY,wBAAwB,IAAI,WAAW,EAAE;4BACvF,yBAAyB,CAAC,SAAS,CACjC,WAAW,EACX,CAAC,EACD,CAAC,CACF,CAAC;yBACH;wBAED,UAAU,CAAC,GAAG,CAAC,mBAAmB,CAAC,CAAC;wBACpC,UAAU,CAAC,KAAK,CAAC,mBAAmB,CAAC,CAAC;;;;;KACvC;IAED;;MAEE;IACM,iDAAmB,GAA3B,UAA4B,MAA2E;QACrG,IAAI,MAAM,YAAY,gBAAgB,EAAE;YACtC,OAAO,EAAE,KAAK,EAAE,MAAM,CAAC,UAAU,EAAE,MAAM,EAAE,MAAM,CAAC,WAAW,EAAE,CAAC;SACjE;QAED,IAAI,MAAM,YAAY,UAAU,EAAE;YAChC,OAAO,EAAE,KAAK,EAAE,MAAM,CAAC,YAAY,EAAE,MAAM,EAAE,MAAM,CAAC,aAAa,EAAE,CAAC;SACrE;QAED,OAAO,EAAE,KAAK,EAAE,MAAM,CAAC,KAAK,EAAE,MAAM,EAAE,MAAM,CAAC,MAAM,EAAE,CAAC;IACxD,CAAC;IACH,0BAAC;AAAD,CAAC,AAzND,CAAoL,qBAAS,GAyN5L;AAzNY,kDAAmB","sourcesContent":["import { MASK_BLUR_RADIUS } from '../../constants';\nimport { Benchmark } from '../../utils/Benchmark';\nimport { version } from '../../utils/version';\nimport { InputFrame } from '../../types';\nimport { Processor } from '../Processor';\nimport { BackgroundProcessorPipeline, BackgroundProcessorPipelineProxy } from './pipelines/backgroundprocessorpipeline';\n\n/**\n * @private\n */\nexport interface BackgroundProcessorOptions {\n  /**\n   * The VideoProcessors load assets dynamically depending on certain browser features.\n   * You need to serve all the assets and provide the root path so they can be referenced properly.\n   * These assets can be copied from the `dist/build` folder which you can add as part of your deployment process.\n   * @example\n   * <br/>\n   * <br/>\n   * For virtual background:\n   * <br/>\n   *\n   * ```ts\n   * const virtualBackground = new VirtualBackgroundProcessor({\n   *   assetsPath: 'https://my-server-path/assets',\n   *   backgroundImage: img,\n   * });\n   * await virtualBackground.loadModel();\n   * ```\n   *\n   * <br/>\n   * For blur background:\n   * <br/>\n   *\n   * ```ts\n   * const blurBackground = new GaussianBlurBackgroundProcessor({\n   *   assetsPath: 'https://my-server-path/assets'\n   * });\n   * await blurBackground.loadModel();\n   * ```\n   */\n  assetsPath: string;\n\n  /**\n   * Whether the pipeline should calculate the person mask without\n   * waiting for the current input frame to be downscaled. Setting\n   * this to true will potentially increase the output frame rate at\n   * the expense of a slight trailing effect around the person mask\n   * (Chrome only).\n   * @default\n   * ```html\n   * false\n   * ```\n   */\n  deferInputFrameDownscale?: boolean;\n\n  /**\n   * The blur radius to use when smoothing out the edges of the person's mask.\n   * @default\n   * ```html\n   * 8\n   * ```\n   */\n  maskBlurRadius?: number;\n\n  /**\n   * Whether to use a web worker (Chrome only).\n   * @default\n   * ```html\n   * true\n   * ```\n   */\n  useWebWorker?: boolean;\n}\n\n/**\n * @private\n */\nexport class BackgroundProcessor<T extends BackgroundProcessorPipeline | BackgroundProcessorPipelineProxy = BackgroundProcessorPipeline | BackgroundProcessorPipelineProxy> extends Processor {\n  protected readonly _assetsPath: string;\n  protected readonly _backgroundProcessorPipeline: T;\n\n  private readonly _benchmark: Benchmark;\n  private _deferInputFrameDownscale: boolean = false;\n  private readonly _inputFrameCanvas: OffscreenCanvas = new OffscreenCanvas(1, 1);\n  private readonly _inputFrameContext: OffscreenCanvasRenderingContext2D = this._inputFrameCanvas.getContext('2d', { willReadFrequently: true })!;\n  private _isSimdEnabled: boolean | null = null;\n  private _maskBlurRadius: number = MASK_BLUR_RADIUS;\n  private _outputFrameBuffer: HTMLCanvasElement | null = null;\n  private _outputFrameBufferContext: CanvasRenderingContext2D | ImageBitmapRenderingContext | null = null;\n\n  // This version is read by the Video SDK\n  // tslint:disable-next-line no-unused-variable\n  private readonly _version: string = version;\n\n  protected constructor(\n    backgroundProcessorPipeline: T,\n    options: BackgroundProcessorOptions\n  ) {\n    super();\n\n    const {\n      assetsPath,\n      deferInputFrameDownscale = this._deferInputFrameDownscale,\n      maskBlurRadius = this._maskBlurRadius\n    } = options;\n\n    if (typeof assetsPath !== 'string') {\n      throw new Error('assetsPath parameter must be a string');\n    }\n\n    // Ensures assetsPath ends with a trailing slash ('/').\n    this._assetsPath = assetsPath.replace(/([^/])$/, '$1/');\n    this._backgroundProcessorPipeline = backgroundProcessorPipeline;\n    // @ts-expect-error - _benchmark is a private property in the pipeline classes definition\n    this._benchmark = this._backgroundProcessorPipeline._benchmark;\n    this.deferInputFrameDownscale = deferInputFrameDownscale;\n    this.maskBlurRadius = maskBlurRadius;\n  }\n\n  /**\n   * Whether the pipeline is calculating the person mask without\n   * waiting for the current input frame to be downscaled (Chrome only).\n   */\n  get deferInputFrameDownscale(): boolean {\n    return this._deferInputFrameDownscale;\n  }\n\n  /**\n   * Toggle whether the pipeline should calculate the person mask\n   * without waiting for the current input frame to be downscaled\n   * (Chrome only).\n   */\n  set deferInputFrameDownscale(defer: boolean) {\n    if (typeof defer !== 'boolean') {\n      console.warn('Provided deferInputFrameDownscale is not a boolean.');\n      defer = this._deferInputFrameDownscale;\n    }\n    if (this._deferInputFrameDownscale !== defer) {\n      this._deferInputFrameDownscale = defer;\n      this._backgroundProcessorPipeline.setDeferInputFrameDownscale(\n        this._deferInputFrameDownscale\n      ).catch(() => {\n        /* noop */\n      });\n    }\n  }\n\n  /**\n   * The current blur radius when smoothing out the edges of the person's mask.\n   */\n  get maskBlurRadius(): number {\n    return this._maskBlurRadius;\n  }\n\n  /**\n   * Set a new blur radius to be used when smoothing out the edges of the person's mask.\n   */\n  set maskBlurRadius(radius: number) {\n    if (typeof radius !== 'number' || radius < 0) {\n      console.warn(`Valid mask blur radius not found. Using ${MASK_BLUR_RADIUS} as default.`);\n      radius = MASK_BLUR_RADIUS;\n    }\n    if (this._maskBlurRadius !== radius) {\n      this._maskBlurRadius = radius;\n      this._backgroundProcessorPipeline\n        .setMaskBlurRadius(this._maskBlurRadius)\n        .catch(() => {\n          /* noop */\n        });\n    }\n  }\n\n  /**\n   * Load the segmentation model.\n   * Call this method before attaching the processor to ensure\n   * video frames are processed correctly.\n   */\n  async loadModel(): Promise<void> {\n    this._isSimdEnabled = await this\n      ._backgroundProcessorPipeline\n      .loadTwilioTFLite();\n  }\n\n  /**\n   * Apply a transform to the background of an input video frame and leaving\n   * the foreground (person(s)) untouched. Any exception detected will\n   * result in the frame being dropped.\n   * @param inputFrameBuffer - The source of the input frame to process.\n   * <br/>\n   * <br/>\n   * [OffscreenCanvas](https://developer.mozilla.org/en-US/docs/Web/API/OffscreenCanvas) - Good for canvas-related processing\n   * that can be rendered off screen.\n   * <br/>\n   * <br/>\n   * [HTMLCanvasElement](https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement) - This is recommended on browsers\n   * that doesn't support `OffscreenCanvas`, or if you need to render the frame on the screen.\n   * <br/>\n   * <br/>\n   * [HTMLVideoElement](https://developer.mozilla.org/en-US/docs/Web/API/HTMLVideoElement)\n   * <br/>\n   * <br/>\n   * [VideoFrame](https://developer.mozilla.org/en-US/docs/Web/API/VideoFrame) - Recommended on browsers that support the\n   * [Insertable Streams API](https://developer.mozilla.org/en-US/docs/Web/API/Insertable_Streams_for_MediaStreamTrack_API).\n   * <br/>\n   * @param outputFrameBuffer - The output frame buffer to use to draw the processed frame.\n   */\n  async processFrame(\n    inputFrameBuffer: OffscreenCanvas | HTMLCanvasElement | HTMLVideoElement | VideoFrame,\n    outputFrameBuffer: HTMLCanvasElement\n  ): Promise<void> {\n    if (!inputFrameBuffer || !outputFrameBuffer) {\n      throw new Error('Missing input or output frame buffer');\n    }\n\n    const {\n      _backgroundProcessorPipeline,\n      _benchmark,\n      _outputFrameBufferContext\n    } = this;\n\n    _benchmark.end('captureFrameDelay');\n    _benchmark.end('totalProcessingDelay');\n    _benchmark.start('totalProcessingDelay');\n    _benchmark.start('processFrameDelay');\n\n    // Extract dimensions based on input frame buffer type\n    const {\n      width: captureWidth,\n      height: captureHeight\n    } = this._getFrameDimensions(inputFrameBuffer);\n\n    if (this._outputFrameBuffer !== outputFrameBuffer) {\n      this._outputFrameBuffer = outputFrameBuffer;\n      this._outputFrameBufferContext = outputFrameBuffer.getContext('2d')\n        || outputFrameBuffer.getContext('bitmaprenderer');\n    }\n    if (this._inputFrameCanvas.width !== captureWidth) {\n      this._inputFrameCanvas.width = captureWidth;\n    }\n    if (this._inputFrameCanvas.height !== captureHeight) {\n      this._inputFrameCanvas.height = captureHeight;\n    }\n\n    // For HTMLVideoElement, we need to draw it to a canvas first\n    // For other input types (OffscreenCanvas, HTMLCanvasElement, VideoFrame), we can use them directly\n    let inputFrame: InputFrame;\n    if (inputFrameBuffer instanceof HTMLVideoElement) {\n      this._inputFrameContext.drawImage(inputFrameBuffer, 0, 0);\n      inputFrame = this._inputFrameCanvas;\n    } else {\n      inputFrame = inputFrameBuffer;\n    }\n\n    // Process the input frame through the appropriate pipeline and return the processed frame\n    const outputFrame = _backgroundProcessorPipeline instanceof BackgroundProcessorPipeline\n      ? await _backgroundProcessorPipeline.render(inputFrame)\n      : await _backgroundProcessorPipeline.render(\n          inputFrame instanceof OffscreenCanvas\n            ? inputFrame.transferToImageBitmap()\n            : inputFrame as VideoFrame // TODO(lrivas): Review why we need to cast to VideoFrame, this breaks when using 'canvas' as inputFrameBufferType\n          );\n\n    // Render the processed frame through the output frame buffer context\n    if (_outputFrameBufferContext instanceof ImageBitmapRenderingContext) {\n      const outputBitmap = outputFrame instanceof OffscreenCanvas\n        ? outputFrame.transferToImageBitmap()\n        : outputFrame;\n      _outputFrameBufferContext.transferFromImageBitmap(outputBitmap);\n    } else if (_outputFrameBufferContext instanceof CanvasRenderingContext2D && outputFrame) {\n      _outputFrameBufferContext.drawImage(\n        outputFrame,\n        0,\n        0\n      );\n    }\n\n    _benchmark.end('processFrameDelay');\n    _benchmark.start('captureFrameDelay');\n  }\n\n  /**\n   * Gets the dimensions of a frame buffer based on its type\n  */\n  private _getFrameDimensions(buffer: OffscreenCanvas | HTMLCanvasElement | HTMLVideoElement | VideoFrame): { width: number, height: number } {\n    if (buffer instanceof HTMLVideoElement) {\n      return { width: buffer.videoWidth, height: buffer.videoHeight };\n    }\n    \n    if (buffer instanceof VideoFrame) {\n      return { width: buffer.displayWidth, height: buffer.displayHeight };\n    }\n    \n    return { width: buffer.width, height: buffer.height };\n  }\n}\n"]}